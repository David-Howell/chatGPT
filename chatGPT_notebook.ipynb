{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "# So I asked chatGPT\n",
    "\n",
    "<head>\n",
    "<style>\n",
    "  div {\n",
    "    max-width: 800px;\n",
    "  min-width: 100px;\n",
    "  background-color: white;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<font color=\"black\">\n",
    "\n",
    "  ***\n",
    "## Introduction\n",
    "  ***\n",
    "<b>Below is the tale of my experience asking chatGPT how it would approach a Data Science problem. Namely, the classic Titanic classification problem.\n",
    "<br><br>\n",
    "Now this is hardly an exhaustive exploration of this nitch of the technology, I started with as simple a one-sentence question as I could. And asked chatGPT to give it to me in python; that's it.\n",
    "And though I did NOT explicitly ask for an MVP, that is exactly what it gave me.\n",
    "<br><br>\n",
    "While there are multiple caveats—at least some of which we address—the overall performance of chatGPT in giving decent code with comments on this niche topic is really impressive.\n",
    "\n",
    "* [must have titanic.csv](#init)\n",
    "* I hurdled the column names that I had changed\n",
    "* I had to prompt it for a validation set, which it did incredibly well... And explained why we were doing it.\n",
    "* The 2 errors that were overcome by chatGPT/ which were really preprocessing, which I never asked it to do in the first sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<head>\n",
    "<style>\n",
    "  div {\n",
    "    max-width: 800px;\n",
    "  min-width: 100px;\n",
    "  background-color: white;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<font size=\"4\">\n",
    "<font color=\"black\">\n",
    "\n",
    "  ***\n",
    "<a id=\"init\"></a>\n",
    "\n",
    "## Init ask:\n",
    "  ***\n",
    "\n",
    "To start off I was trying to stay as simple as possible in my request to chatGPT.\n",
    "<br><br>\n",
    "I asked it how it would use <u>EDA</u> and <u>ML models</u> to classify the passengers, and that it use Python to show me.\n",
    "<br><br>\n",
    "That's it.  And that's all it gives me right away. I'm guessing that because I didn't ask it acquire or prepare the data, it assumed that I had already done that sufficiently.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "\n",
    "<b> <u>Me</u>: </b> \n",
    "<font color=\"blue\">\n",
    "<br><br>\n",
    "  how would you use exploratory data analysis and machine learning models to classify the passengers of the titanic as passengers who survived and passengers that perished? Please show me using python\n",
    "<font color=\"black\">\n",
    "<br><br>\n",
    "<b> <u>chatGPT</u>: </b> \n",
    "<font color=\"green\">\n",
    "<br><br>\n",
    "  To classify the passengers of the Titanic as survivors and those who perished, we would first need to obtain the data on the passengers. This data could include information such as their age, sex, cabin class, and whether they survived or not.\n",
    "\n",
    "Next, we would perform exploratory data analysis on the data to gain insights and identify patterns. This could involve visualizing the data using graphs and charts, calculating summary statistics, and looking for correlations between different variables.\n",
    "\n",
    "Once we have a good understanding of the data, we would then use a machine learning algorithm to train a model on the data. This could be a classification algorithm such as logistic regression, decision trees, or support vector machines. The goal of the model would be to learn the relationship between the different variables in the data and the outcome (whether a passenger survived or not).\n",
    "\n",
    "To train the model, we would split the data into a training set and a test set. The model would be trained on the training set, and then its performance would be evaluated on the test set. This would give us an idea of how well the model is able to classify the passengers as survivors or those who perished.\n",
    "\n",
    "Here is an example of how this could be done in Python:\n",
    "\n",
    "<font size=\"2\">\n",
    "\n",
    "\n",
    "> ```python\n",
    "> # Import libraries\n",
    "> import pandas as pd\n",
    "> import matplotlib.pyplot as plt\n",
    "> from sklearn.model_selection import train_test_split\n",
    "> from sklearn.linear_model import LogisticRegression\n",
    "> \n",
    "> # Load the data\n",
    "> data = pd.read_csv('titanic.csv')\n",
    "> \n",
    "> # Perform exploratory data analysis\n",
    "> data.describe()\n",
    "> data.groupby(['Sex', 'Survived']).size().plot(kind='bar')\n",
    "> \n",
    "> # Prepare the data for modeling\n",
    "> X = data[['Age', 'Sex', 'Pclass']]\n",
    "> y = data['Survived']\n",
    "> \n",
    "> # Split the data into a training set and a test set\n",
    "> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "> \n",
    "> # Train a logistic regression model\n",
    "> model = LogisticRegression()\n",
    "> model.fit(X_train, y_train)\n",
    "> \n",
    "> # Evaluate the model on the test set\n",
    "> accuracy = model.score(X_test, y_test)\n",
    "> print('Accuracy:', accuracy)\n",
    "> ```\n",
    "\n",
    "<br><br>\n",
    "<font size=\"4\">\n",
    "This is just one possible approach to solving this problem using exploratory data analysis and machine learning. There are many other algorithms and techniques that could also be used to classify the passengers of the Titanic.\n",
    "<br><br>\n",
    "<font color=\"black\">\n",
    "<a id=\"init_reaction\"></a>\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<head>\n",
    "<style>\n",
    "  div {\n",
    "    max-width: 800px;\n",
    "  min-width: 100px;\n",
    "  background-color: white;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<font size=\"4\">\n",
    "<font color=\"black\">\n",
    "\n",
    "## Init Reaction:\n",
    "***\n",
    "\n",
    "So the first time reading through this, I'm just pretty much <font size=\"5\">BLOWN AWAY<font size=\"4\">.\n",
    "<br><br>\n",
    "I mean I'd seen some of the copilot stuff, and I knew going in that it was going to give me something that should be at least a semblance of sensible. But this is on another level.\n",
    "<br><br>\n",
    "We'll dig a little deeper here in a minute, but let's first just look at some of the things it did right, and well.\n",
    "  - Picked some features\n",
    "    It went ahead and grabbed 3 features to use and our target variable. Very much the way anyone might give an \"example\" case or go for an MVP.\n",
    "  - Simple and succinct\n",
    "    It describes the basic idea of the processes of EDA and Modeling and the goal.\n",
    "  - Code\n",
    "    Clean, commented, conventional imports, uses bracket notation\n",
    "\n",
    "Reviewing chatGPT's code I realized it wanted me to provide it with the titanic.csv—which I conviently still have sitting in my classification-exercises folder...\n",
    "> `$ cp ~/.../titanic.csv titanic.csv`\n",
    "\n",
    "Additionally, I know that my `titanic.csv` already has lowercase column names, but I figure since that's something I changed I can just fix that myself.\n",
    "<br><br>\n",
    "Before running this though, I just don't feel right running any experiments withouth having a validation set and test set—idk I was just raised as a Data Scientist this way.\n",
    "\n",
    "***\n",
    "## Ask for an Adjustment\n",
    "***\n",
    "Instead of taking the initial copy pasta to my plate and cutting and swirling it myself, I decided to ask chatGPT how it would update the code to include a validatioin\n",
    "\n",
    "<font color=\"black\">\n",
    "<b> <u>Me</u>:</b> \n",
    "<br><br>\n",
    "<font color=\"blue\">\n",
    "What if I asked you to run the exploration and modeling on a training set while holding out both a validation set and a test set. how would you update the code?\n",
    "<br><br>\n",
    "<font color=\"black\">\n",
    "<b><u> chatGPT</u>: </b>\n",
    "<br><br> \n",
    "<font color=\"green\">\n",
    "To run the exploratory data analysis and modeling on a training set while holding out a validation set and a test set, you would need to split the data into three sets: a training set, a validation set, and a test set.\n",
    "\n",
    "The training set would be used to train the model, the validation set would be used to evaluate the model and tune its hyperparameters, and the test set would be used to evaluate the final performance of the model.\n",
    "\n",
    "Here is how this could be done in Python using `scikit-learn`:\n",
    "\n",
    "<font size=\"2\">\n",
    "\n",
    "> ```python\n",
    "> \n",
    ">     # Import libraries\n",
    ">     import pandas as pd\n",
    ">     import matplotlib.pyplot as plt\n",
    ">     from sklearn.model_selection import train_test_split\n",
    ">     from sklearn.linear_model import LogisticRegression\n",
    "> \n",
    ">     # Load the data\n",
    ">     data = pd.read_csv('titanic.csv')\n",
    "> \n",
    ">     # Perform exploratory data analysis\n",
    ">     data.describe()\n",
    ">     data.groupby(['Sex', 'Survived']).size().plot(kind='bar')\n",
    "> \n",
    ">     # Prepare the data for modeling\n",
    ">     X = data[['Age', 'Sex', 'Pclass']]\n",
    ">     y = data['Survived']\n",
    "> \n",
    ">     # Split the data into a training set, a validation set, and a test set\n",
    ">     # Stratify the splits by the target variable\n",
    ">     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    ">     X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, stratify=y_val)\n",
    "> \n",
    ">     # Train a logistic regression model\n",
    ">     model = LogisticRegression()\n",
    ">     model.fit(X_train, y_train)\n",
    "> \n",
    ">     # Evaluate the model on the validation set\n",
    ">     accuracy = model.score(X_val, y_val)\n",
    ">     print('Accuracy:', accuracy)\n",
    "> \n",
    ">     # Tune the model's hyperparameters using the validation set\n",
    ">     # ...\n",
    "> \n",
    ">     # Evaluate the final model on the test set\n",
    ">     accuracy = model.score(X_test, y_test)\n",
    ">     print('Accuracy:', accuracy)\n",
    "> ```\n",
    "***\n",
    "<br>\n",
    "<font size=\"4\">\n",
    "\n",
    "In this code, the data is first split into a training set, a validation set, and a test set using the train_test_split function from scikit-learn. The training set is used to train the model, the validation set is used to evaluate the model and tune its hyperparameters, and the test set is used to evaluate the final performance of the model.\n",
    "\n",
    "Note that this is just one possible approach to splitting the data into training, validation, and test sets. There are many other ways to do this, and the specific method used may depend on the characteristics of the data and the goals of the analysis.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('titanic.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.602694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.489615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       passenger_id    survived      pclass         age       sibsp  \\\n",
       "count    891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean     445.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std      257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min        0.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%      222.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%      445.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%      667.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max      890.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            parch        fare       alone  \n",
       "count  891.000000  891.000000  891.000000  \n",
       "mean     0.381594   32.204208    0.602694  \n",
       "std      0.806057   49.693429    0.489615  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    7.910400    0.000000  \n",
       "50%      0.000000   14.454200    1.000000  \n",
       "75%      0.000000   31.000000    1.000000  \n",
       "max      6.000000  512.329200    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform exploratory data analysis\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passenger_id', 'survived', 'pclass', 'sex', 'age', 'sibsp', 'parch',\n",
       "       'fare', 'embarked', 'class', 'deck', 'embark_town', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sex,survived'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data.groupby(['sex', 'survived']).size().plot(kind='bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data.Sex field to a numerical value\n",
    "le = LabelEncoder()\n",
    "le.fit(data.sex)\n",
    "data.sex = le.transform(data.sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the data.Age field with the median age\n",
    "data['age'] = data['age'].fillna(data['age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for modeling\n",
    "X = data[['age', 'sex', 'pclass']]\n",
    "y = data['survived']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set, a validation set, and a test set\n",
    "# Stratify the splits by the target variable\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, stratify=y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7640449438202247\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "accuracy = model.score(X_val, y_val)\n",
    "print('Accuracy:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the model's hyperparameters using the validation set\n",
    "# ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8111111111111111\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model on the test set\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
